{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58173b26",
   "metadata": {},
   "source": [
    "# Generative AI Tools: A Deep Dive into LangChain and yFinance\n",
    "**Author**: Mahdy Mokhtari  \n",
    "**Date**: 6 Azar 1404 \n",
    "**Course**: GenAI - Tools\n",
    "\n",
    "## Overview\n",
    "This notebook explores the integration of the **LangChain** framework with **yFinance**, a Python library used to fetch real-time stock prices. The aim of this project is to demonstrate how to build an interactive agent using these tools that can fetch stock prices dynamically and respond to user queries.\n",
    "\n",
    "### Key Technologies Used:\n",
    "1. **LangChain Framework**:  \n",
    "   LangChain is a powerful framework that allows the integration of external tools and APIs into AI models. It facilitates the creation of custom agents that can combine the power of various Python libraries and language models (LLMs). In this project, LangChain is used to wrap Python functions and expose them as tools that can be invoked by AI models.\n",
    "\n",
    "2. **yFinance**:  \n",
    "   `yFinance` is a library that simplifies access to financial data from Yahoo Finance. This tool is leveraged in the notebook to retrieve real-time stock prices, offering an easy way to access and use historical market data for financial analysis.\n",
    "\n",
    "3. **Python Programming**:  \n",
    "   The core of the project is based on Python, a versatile language widely used in data science, AI, and finance. The Python code is designed to interact with the Yahoo Finance API via `yFinance` and to integrate seamlessly with the LangChain framework to facilitate natural language-based querying.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c6ba2",
   "metadata": {},
   "source": [
    "### Function to get Stock Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897de411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a05603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee7b18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class GetStockInput(BaseModel):\n",
    "    \"\"\"Schema for stock price input.\"\"\"\n",
    "    ticker_symbol: str = Field(..., description=\"The stock ticker symbol (e.g., 'AAPL', 'GOOGL')\")    \n",
    "\n",
    "@tool(args_schema=GetStockInput, return_direct=True, description=\"Fetches the latest closing stock price for a given ticker symbol using yFinance.\")\n",
    "def get_stock_price(ticker_symbol: str) -> str:\n",
    "    data = yf.Ticker(ticker_symbol).history(period=\"1d\")\n",
    "    price = data['Close'].iloc[-1]\n",
    "    return f\"The current price of {ticker_symbol.upper()} is ${price:.2f}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AddInput(BaseModel):\n",
    "    \"\"\"Add two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "@tool(\"add-tool\", args_schema=AddInput, return_direct=True, description=\"Adds two integers together and returns the result.\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "tools = [get_stock_price, add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22775912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.3\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89df475",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.prompts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM, pipeline\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.prompts'"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"gpt2\")   # free LLM\n",
    "\n",
    "# llm_with_tools = llm.bind_tools(tools)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f7684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm.invoke(\"\"\"135165435131313322323130130123 + 1233255552224463222111111\"\"\")\n",
    "#correct response = 13602805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"\"\"135165435131313322323130130123 + 1233255552224463222111111\"\"\", tools=tools).content\n",
    "# .tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3704123",
   "metadata": {},
   "source": [
    "### The Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages.tool_message import ToolMessage\n",
    "\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful, precise, and reliable AI assistant.\n",
    "\n",
    "Your goals:\n",
    "1. Answer the user's query as accurately, concisely, and factually as possible.\n",
    "2. If a tool is available AND it is appropriate for the user's request,\n",
    "   you MUST call the tool using the correct function name and JSON arguments.\n",
    "3. If no tool is relevant, answer directly in natural language.\n",
    "4. If multiple tools could be relevant, choose the single best one.\n",
    "5. Before calling a tool, verify that the required arguments are present and valid.\n",
    "6. Never hallucinate tool names, arguments, or fields.\n",
    "\n",
    "How you should behave when deciding between answering or calling a tool:\n",
    "- If the user asks for **retrieval, calculation, an action, or external data**, use a tool.\n",
    "- If the user asks a **knowledge, reasoning, or explanation question**, respond normally.\n",
    "- When calling a tool, output ONLY the tool call in the required JSON formatâ€”no extra text.\n",
    "\n",
    "If extra context is provided below, use it when helpful.\n",
    "\n",
    "# Additional Context:\n",
    "{context}\n",
    "\n",
    "\"\"\"\n",
    "context = \"The user may ask for stock prices or to add two integers.\"\n",
    "\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "# User Query:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "query = \"What is the current stock price of Amazon?\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYSTEM_PROMPT),\n",
    "    (\"user\", USER_PROMPT),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# messages is just for the chat history\n",
    "messages = [prompt.format_messages(context=context, query=query)[0]]\n",
    "\n",
    "ai_msg = llm.invoke(messages, tools=tools)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    print(tool_call)\n",
    "    print(\"Funciton/Tool name:\", tool_call[\"name\"])\n",
    "    selected_tool = {\"add\": add, \"get_stock_price\": get_stock_price, 'add-tool': add, \"get_stock_price-tool\": get_stock_price}[tool_call[\"name\"].lower()]\n",
    "\n",
    "    print(\"tool args:\", tool_call[\"args\"])\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "    print(\"tool output:\", tool_output)\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
